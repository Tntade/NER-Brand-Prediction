{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>2021/2/9 本版本<br>(1)部分底层数据重清洗，做到brand和goods中的一致;<br>(2)数据增强以后测试少样本品牌的ner预测;<br><br>下次版本<br>(1)加入天猫/淘宝/京东等第三方统计好的我们没有的品牌；<br>(2)确认所有品牌是真实有效的，进行人工核检;<br>(3)如果上面版本测试的数据增强的效果可以的话，则购买第三方完整的品牌数据后做数据增强;<br><br>下下次版本<br>(1)加入品类标签,CNT-B,CNT-I;<br>(2)制作品牌+国家的映射表，直接自动化处理dupont的国家的5个master字段；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sqlalchemy import create_engine\n",
    "import time,gc,os,re,sys,re,jieba,os,math\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_cols(df):\n",
    "    cols=df.columns.tolist()\n",
    "    leng=int(len(cols)/5)+1\n",
    "    for i in range(leng):\n",
    "        tmp=df.iloc[:5,i*6:(i+1)*6]\n",
    "        print(tmp.head())\n",
    "        print('-'*30)\n",
    "\n",
    "def check_miss_ratio(df):\n",
    "    missdf=pd.isnull(df).sum().reset_index(name='miss_cnt')\n",
    "    missdf.columns=['col','miss_cnt']\n",
    "    missdf['miss_ratio']=missdf['miss_cnt']/df.shape[0]\n",
    "    print(missdf.head(20))\n",
    "    return missdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "for i in range(11,44,11):\n",
    "    tmp=pd.read_csv('d_platform_goods_%d.csv'%i,encoding='utf-8-sig')\n",
    "    df=pd.concat([df,tmp],axis=0)\n",
    "df=df.drop_duplicates().reset_index(drop=True)\n",
    "print(df.shape)\n",
    "print(df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path='./data/'\n",
    "# files=os.listdir(path)\n",
    "# print(files)\n",
    "\n",
    "# brand=pd.read_excel(path+'d_master_brand.xls')\n",
    "# cols=['master_brand_key', 'master_brand_name', 'master_brand_cn', 'master_brand_en', 'brand_company_cn', 'brand_company_en']\n",
    "# brand=brand[cols].drop_duplicates().reset_index(drop=True)\n",
    "# print(brand.shape)\n",
    "# print(brand['master_brand_key'].nunique())\n",
    "# print(brand.head(3))\n",
    "\n",
    "# import_brand=pd.read_excel(path+'d_master_brand_import.xls')\n",
    "# cols=['master_brand_key', 'master_brand_cn', 'master_brand_en', 'brand_company_cn', 'brand_company_en', 'cust_categ_l2_id',\n",
    "#       'cust_categ_l2_cn', 'match_keywords_1', 'match_keywords_2', 'match_keywords_3', 'anti_match_keywords_1',\n",
    "#       'anti_match_keywords_2', 'anti_match_keywords_3']\n",
    "# import_brand=import_brand[cols].drop_duplicates().reset_index(drop=True)\n",
    "# print(import_brand.shape)\n",
    "# print(import_brand.head(3))\n",
    "# print(pd.isnull(import_brand).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4522820, 23)\n",
      "4519986\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df['platform_goods_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['platform_goods_id','platform_goods_key'],ascending=True).drop_duplicates(subset=['platform_goods_id'],keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4519986, 23)\n",
      "4519986\n",
      "4519986\n"
     ]
    }
   ],
   "source": [
    "df=df[df['platform_goods_id'].notnull()]\n",
    "print(df.shape)\n",
    "print(df['platform_goods_key'].nunique())\n",
    "print(df['platform_goods_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4519986, 15)\n",
      "4519986\n",
      "4519986\n"
     ]
    }
   ],
   "source": [
    "cols=['platform_goods_key', 'platform_goods_id', 'platform_goods_name',\n",
    "      'platform_brand_key', 'platform_brand_name', 'master_brand_key', 'master_brand_name_cn', 'master_brand_name_en',\n",
    "      'master_brand_company_cn', 'master_brand_company_en', 'platform_shop_key', 'platform_shop_name', 'platform_name_en',\n",
    "      'platform_name_cn', 'platform_categ_key']\n",
    "df=df[cols].drop_duplicates().reset_index(drop=True)\n",
    "print(df.shape)\n",
    "print(df['platform_goods_key'].nunique())\n",
    "print(df['platform_goods_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        col  miss_cnt  miss_ratio\n",
      "0        platform_goods_key         0    0.000000\n",
      "1         platform_goods_id         0    0.000000\n",
      "2       platform_goods_name        55    0.000012\n",
      "3        platform_brand_key    587245    0.129922\n",
      "4       platform_brand_name    586988    0.129865\n",
      "5          master_brand_key         0    0.000000\n",
      "6      master_brand_name_cn         0    0.000000\n",
      "7      master_brand_name_en         0    0.000000\n",
      "8   master_brand_company_cn         0    0.000000\n",
      "9   master_brand_company_en         0    0.000000\n",
      "10        platform_shop_key         0    0.000000\n",
      "11       platform_shop_name     32139    0.007110\n",
      "12         platform_name_en         0    0.000000\n",
      "13         platform_name_cn         0    0.000000\n",
      "14       platform_categ_key         0    0.000000\n"
     ]
    }
   ],
   "source": [
    "missdf=check_miss_ratio(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['master_brand_name_cn'].str.contains('其他',na=False),'master_brand_name_cn']=np.nan\n",
    "df.loc[df['master_brand_name_en'].str.contains('OTHERS',na=False),'master_brand_name_en']=np.nan\n",
    "df.loc[df['platform_brand_name'].str.contains('其他',na=False),'platform_brand_name']=np.nan\n",
    "df.loc[df['master_brand_company_cn'].str.contains('其他',na=False),'master_brand_company_cn']=np.nan\n",
    "df.loc[df['master_brand_company_en'].str.contains('OTHERS',na=False),'master_brand_company_en']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       col  miss_cnt  miss_ratio\n",
      "0        platform_goods_id         0    0.000000\n",
      "1      platform_goods_name        55    0.000012\n",
      "2      platform_brand_name    709833    0.157043\n",
      "3     master_brand_name_cn   1291461    0.285722\n",
      "4     master_brand_name_en   1291505    0.285732\n",
      "5  master_brand_company_cn   1291462    0.285723\n",
      "6  master_brand_company_en   1291506    0.285732\n"
     ]
    }
   ],
   "source": [
    "missdf=check_miss_ratio(df[['platform_goods_id','platform_goods_name', 'platform_brand_name', 'master_brand_name_cn', 'master_brand_name_en','master_brand_company_cn','master_brand_company_en']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ['platform_goods_name', 'platform_brand_name', 'master_brand_name_cn', 'master_brand_name_en','master_brand_company_cn','master_brand_company_en']:\n",
    "    df.loc[df[col].notnull(),col]=df[df[col].notnull()][col].apply(lambda x:str(x).upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4519931, 15)\n",
      "4519931\n",
      "4519931\n"
     ]
    }
   ],
   "source": [
    "df=df[df['platform_goods_name'].notnull()]\n",
    "print(df.shape)\n",
    "print(df['platform_goods_id'].nunique())\n",
    "print(df['platform_goods_key'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        col  miss_cnt  miss_ratio\n",
      "0        platform_goods_key         0    0.000000\n",
      "1         platform_goods_id         0    0.000000\n",
      "2       platform_goods_name         0    0.000000\n",
      "3        platform_brand_key    587202    0.129914\n",
      "4       platform_brand_name    709790    0.157036\n",
      "5          master_brand_key         0    0.000000\n",
      "6      master_brand_name_cn   1291416    0.285716\n",
      "7      master_brand_name_en   1291460    0.285726\n",
      "8   master_brand_company_cn   1291417    0.285716\n",
      "9   master_brand_company_en   1291461    0.285726\n",
      "10        platform_shop_key         0    0.000000\n",
      "11       platform_shop_name     32139    0.007111\n",
      "12         platform_name_en         0    0.000000\n",
      "13         platform_name_cn         0    0.000000\n",
      "14       platform_categ_key         0    0.000000\n"
     ]
    }
   ],
   "source": [
    "missdf=check_miss_ratio(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   platform_categ_key     cnt\n",
      "0                 594  139754\n",
      "1                 602  137683\n",
      "2                 151  135988\n",
      "3                 597  134868\n",
      "4                 596  122903\n",
      "5                2363  117805\n",
      "6                 162  103135\n",
      "7                 861   91771\n",
      "8                  53   90166\n",
      "9                1125   87145\n"
     ]
    }
   ],
   "source": [
    "tmp=df.groupby('platform_categ_key')['platform_goods_key'].count().reset_index(name='cnt')\n",
    "tmp=tmp.sort_values(by=['cnt'],ascending=False).reset_index(drop=True)\n",
    "print(tmp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   platform_categ_key   cnt\n",
      "0                2363  1125\n",
      "1                 596   990\n",
      "2                 152   941\n",
      "3                  53   910\n",
      "4                 163   868\n",
      "5                1125   819\n",
      "6                1123   790\n",
      "7                 151   764\n",
      "8                 165   757\n",
      "9                2380   744\n"
     ]
    }
   ],
   "source": [
    "tmp=df.groupby('platform_categ_key')['master_brand_name_cn'].nunique().reset_index(name='cnt')\n",
    "tmp=tmp.sort_values(by=['cnt'],ascending=False).reset_index(drop=True)\n",
    "print(tmp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00      1.0\n",
      "0.25      3.0\n",
      "0.50     11.0\n",
      "0.75     32.0\n",
      "1.00    167.0\n",
      "Name: cnt, dtype: float64\n",
      "  master_brand_name_cn  cnt\n",
      "0                 伊蒂之屋  167\n",
      "1                   迪奥  165\n",
      "2                  美宝莲  162\n",
      "3                  资生堂  156\n",
      "4                   魅可  154\n",
      "5                  欧莱雅  154\n",
      "6                  香奈儿  153\n",
      "7                  三熹玉  153\n",
      "8                 雅诗兰黛  152\n",
      "9                 悦诗风吟  148\n"
     ]
    }
   ],
   "source": [
    "tmp=df.groupby('master_brand_name_cn')['platform_categ_key'].nunique().reset_index(name='cnt')\n",
    "tmp=tmp.sort_values(by=['cnt'],ascending=False).reset_index(drop=True)\n",
    "print(tmp['cnt'].quantile([0,0.25,0.5,0.75,1]))\n",
    "print(tmp.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355\n"
     ]
    }
   ],
   "source": [
    "print(tmp[tmp['cnt']==1]['master_brand_name_cn'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['雨潼', '醫美保健', '霏丝佳', 'RFB', 'SEA GLASS', 'SINIL PHARM', '霍氏', 'SANOFLORE', 'SUEE', '零语']\n"
     ]
    }
   ],
   "source": [
    "print(tmp[tmp['cnt']==1]['master_brand_name_cn'].unique().tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4519931, 8)\n"
     ]
    }
   ],
   "source": [
    "cols=['platform_goods_id','platform_goods_name','platform_brand_name', 'master_brand_name_cn','master_brand_name_en','platform_categ_key',\n",
    "     'master_brand_company_cn','master_brand_company_en']\n",
    "dff=df[cols].drop_duplicates().reset_index(drop=True)\n",
    "dff.columns=['id','desc','brand','brand_cn','brand_en','cate_key','company_cn','company_en']\n",
    "print(dff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    3228515\n",
      "1.0    1291416\n",
      "Name: is_brand_empty, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def clean_str(s):\n",
    "    s=str(s)\n",
    "    s=s.replace(' ','')\n",
    "    return s.upper()\n",
    "\n",
    "for col in ['desc','brand','brand_cn','brand_en','company_cn','company_en']:\n",
    "    dff.loc[dff[col].notnull(),col]=dff[dff[col].notnull()][col].apply(clean_str)\n",
    "\n",
    "dff.loc[dff['brand_cn'].isnull(),'is_brand_empty']=1\n",
    "dff['is_brand_empty']=dff['is_brand_empty'].fillna(0)\n",
    "print(dff['is_brand_empty'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_brand(df):\n",
    "    df['brand_1']=df['brand'].apply(lambda x:'/'.join(x.split('（')))\n",
    "    df['brand_1']=df['brand_1'].apply(lambda x:x.split('）')[0])\n",
    "    df['brand_1']=df['brand_1'].apply(lambda x:'/'.join(x.split('(')))\n",
    "    df['brand_1']=df['brand_1'].apply(lambda x:x.split(')')[0])\n",
    "\n",
    "    df['brand_2']=df['brand_1'].apply(lambda x:x.split('/')[0])\n",
    "    df['brand_3']=df['brand_1'].apply(lambda x:x.split('/')[1] if len(x.split('/'))>=2 else x.split('/')[0])\n",
    "\n",
    "    pattern=re.compile('[\\u4e00-\\u9fa5]')\n",
    "\n",
    "    df['brand_cn_1']=''\n",
    "    df['brand_en_1']=''\n",
    "\n",
    "    df['brand_2_mark']=df['brand_2'].apply(lambda x:re.sub(pattern,'NA',x))\n",
    "    df.loc[df['brand_2_mark'].str.contains('NA'),'brand_cn_1']=df[df['brand_2_mark'].str.contains('NA')]['brand_2']\n",
    "\n",
    "    df.loc[df['brand_cn_1']=='','brand_en_1']=df[df['brand_cn_1']=='']['brand_2']\n",
    "\n",
    "    df['brand_cn_2']=''\n",
    "    df['brand_en_2']=''\n",
    "\n",
    "    df['brand_3_mark']=df['brand_3'].apply(lambda x:re.sub(pattern,'NA',x))\n",
    "    df.loc[df['brand_3_mark'].str.contains('NA'),'brand_cn_2']=df[df['brand_3_mark'].str.contains('NA')]['brand_3']\n",
    "\n",
    "    df.loc[df['brand_cn_2']=='','brand_en_2']=df[df['brand_cn_2']=='']['brand_3']\n",
    "\n",
    "    df['brand_cn_fill']=df['brand_cn_1']\n",
    "    df.loc[df['brand_cn_fill']=='','brand_cn_fill']=df[df['brand_cn_fill']=='']['brand_cn_2']\n",
    "    df['brand_en_fill']=df['brand_en_1']\n",
    "    df.loc[df['brand_en_fill']=='','brand_en_fill']=df[df['brand_en_fill']=='']['brand_en_2']\n",
    "\n",
    "    for col in ['brand_en_fill','brand_en','brand_cn_fill','brand_cn','brand']:\n",
    "        df.loc[df[col]=='',col]=np.nan\n",
    "        df.loc[df[col]=='nan',col]=np.nan\n",
    "        df.loc[df[col]=='NAN',col]=np.nan\n",
    "#     need_cols=['desc','brand','brand_cn','brand_en','brand_key','brand_cn_fill','brand_en_fill','mark']\n",
    "#     df=df[need_cols].drop_duplicates().reset_index(drop=True)\n",
    "    df=df.drop_duplicates().reset_index(drop=True)\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# for col in ['brand','brand_cn','brand_en']:\n",
    "#     df[col]=df[col].astype(str)\n",
    "# df1=split_brand(df)\n",
    "# df1.sample(3)\n",
    "\n",
    "# df.loc[(df['brand_cn'].isnull())&(df['brand_cn_fill'].notnull()),'brand_cn']=df[(df['brand_cn'].isnull())&(df['brand_cn_fill'].notnull())]['brand_cn_fill']\n",
    "# df.loc[(df['brand_en'].isnull())&(df['brand_en_fill'].notnull()),'brand_en']=df[(df['brand_en'].isnull())&(df['brand_en_fill'].notnull())]['brand_en_fill']\n",
    "# df.loc[(df['brand_cn_fill'].isnull())&(df['brand_cn'].notnull()),'brand_cn_fill']=df[(df['brand_cn_fill'].isnull())&(df['brand_cn'].notnull())]['brand_cn']\n",
    "# df.loc[(df['brand_en_fill'].isnull())&(df['brand_en'].notnull()),'brand_en_fill']=df[(df['brand_en_fill'].isnull())&(df['brand_en'].notnull())]['brand_en']\n",
    "# df.loc[(df['brand_cn'].isnull())&(df['brand_en'].notnull()),'brand_cn']=df[(df['brand_cn'].isnull())&(df['brand_en'].notnull())]['brand_en']\n",
    "# df.loc[(df['brand_cn'].notnull())&(df['brand_cn_fill'].isnull()),'brand_cn_fill']=df[(df['brand_cn'].notnull())&(df['brand_cn_fill'].isnull())]['brand_cn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_brand_1(v):\n",
    "    pattern_en='[A-Z\\'\\-\\:\\°\\.\\’]'\n",
    "    unit=re.findall(pattern_en,v)\n",
    "    if len(unit)>0:\n",
    "        en=''.join(unit)\n",
    "    else:\n",
    "        en=np.nan\n",
    "\n",
    "    pattern_cn='[\\u4e00-\\u9fa5]'\n",
    "    unit1=re.findall(pattern_cn,v)\n",
    "    if len(unit1)>0:\n",
    "        cn=''.join(unit1)\n",
    "    else:\n",
    "        cn=np.nan\n",
    "    return en,cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s='DIOR迪奥'\n",
    "# # s='迪奥（DIOR）'\n",
    "# # s=\"D'IOR/迪奥 \"\n",
    "# a,b=split_brand_1(s)\n",
    "# print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff['brand']=dff['brand'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff['brand_en_fill']=dff['brand'].apply(lambda x:split_brand_1(x)[0])\n",
    "dff['brand_cn_fill']=dff['brand'].apply(lambda x:split_brand_1(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff.loc[dff['brand']=='nan','brand']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff.loc[dff['brand']=='','brand']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "desc                    0\n",
       "brand              709790\n",
       "brand_cn          1291416\n",
       "brand_en          1291460\n",
       "cate_key                0\n",
       "company_cn        1291417\n",
       "company_en        1291461\n",
       "is_brand_empty          0\n",
       "brand_en_fill     1605663\n",
       "brand_cn_fill     1710093\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(dff).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10993, 11)\n",
      "(4508938, 11)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#处理比较特别的\n",
    "dff1=dff[(dff['brand'].notnull())&(dff['brand_en_fill'].isnull())&(dff['brand_cn_fill'].isnull())]\n",
    "print(dff1.shape)\n",
    "\n",
    "dff2=dff[~dff['id'].isin(set(dff1['id']))]\n",
    "print(dff2.shape)\n",
    "print(len(dff1)+len(dff2)==len(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_brand_sep(v):\n",
    "    pattern_dig='[0-9]'\n",
    "    unit=re.findall(pattern_dig,v)\n",
    "    if len(unit)>0:\n",
    "        dig=''.join(unit)\n",
    "    else:\n",
    "        dig=np.nan\n",
    "    return dig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "s='1905化妆刷收纳袋套刷单支刷收纳袋EVA袋环保防尘防水'\n",
    "res=split_brand_sep(s)\n",
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "s='化妆刷收纳袋套刷单支刷收纳袋EVA袋环保防尘防水'\n",
    "res=split_brand_sep(s)\n",
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff1['brand_dig']=dff1['brand'].apply(lambda x:split_brand_sep(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #余下的都是日文\n",
    "# check=dff1[dff1['brand_dig'].isnull()]\n",
    "# print(check['brand'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "dt=pd.concat([dff1,dff2],axis=0)\n",
    "print(len(dt)==len(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.to_csv('data_1.csv',index=False,encoding='utf-8-sig')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>others check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"检查补充缺失值的那些brand是否有用\"\"\"\n",
    "# check=dff1[dff1['is_same']==1][['id','brand_cn_fill']].rename(columns={'brand_cn_fill':'brand_cn'})\n",
    "# check['brand_en']=check['brand_cn']\n",
    "# print(check['brand_cn'].nunique())\n",
    "# print(check.shape)\n",
    "# check.head(3)\n",
    "\n",
    "# tmp1=dff2.groupby('brand_cn')['id'].nunique().reset_index(name='cn_cnt')\n",
    "# tmp2=dff2.groupby('brand_en')['id'].nunique().reset_index(name='en_cnt')\n",
    "# checks=check.merge(tmp1,on=['brand_cn'],how='left').merge(tmp2,on=['brand_en'],how='left')\n",
    "# print(checks.head(3))\n",
    "\n",
    "# pd.isnull(checks).sum()\n",
    "\n",
    "# checks.loc[(checks['cn_cnt'].isnull())&(checks['en_cnt'].notnull()),'cn_cnt']=checks[(checks['cn_cnt'].isnull())&(checks['en_cnt'].notnull())]['en_cnt']\n",
    "\n",
    "# pd.isnull(checks).sum()\n",
    "\n",
    "# part1=checks[checks['cn_cnt']>=1]\n",
    "# part2=checks[checks['cn_cnt'].isnull()]\n",
    "# print(len(part1)+len(part2)==len(checks))\n",
    "\n",
    "# print(len(part1)/len(checks))\n",
    "# print(len(part1)/len(checks)*len(checks))\n",
    "# print(len(part2)/len(checks))\n",
    "# print(len(part2)/len(checks)*len(checks))\n",
    "\n",
    "# tt=dff2['is_same'].value_counts().reset_index(name='cnt')\n",
    "# tt.rename(columns={'index':'is_same'},inplace=True)\n",
    "# tt['ratio']=tt['cnt']/len(df1)\n",
    "# tt.head()\n",
    "\n",
    "# \"\"\"\n",
    "# 1.主要查看了master_brand_cn和brand_cn_fill出现不一致的情况，主要原因是：\n",
    "# (1)统一名称不一致，比如佳丽宝和嘉娜宝，相对来说，brand_cn_fill更加精确\n",
    "# (2)处理下CHIOTURE稚优泉这样的情况\n",
    "# (3)brand和series的区别，比如肌肤之钥和资生堂\n",
    "# 结果：相对来说brand_cn_fill更加精确\n",
    "# \"\"\"\n",
    "\n",
    "# check=dff2[dff2['is_same']==0]\n",
    "# check[['desc','brand','brand_cn','brand_en','brand_cn_fill']].head(20)\n",
    "\n",
    "# df2=df.copy()\n",
    "# print(df2.shape)\n",
    "# print(pd.isnull(df2).sum())\n",
    "\n",
    "# \"\"\"其中21.2%通过platform_brand_name进行补充缺失值的品牌的正确与否，其实取决于这个platform_brand_name这个字段的质量；\n",
    "# 如何验证这个补缺以后的brand到底是不是正确呢？\n",
    "# (1)划分为train+test,查看train中的正确率\n",
    "# \"\"\"\n",
    "\n",
    "# train=df2[df2['mark']==0]\n",
    "# valid=df2[(df2['mark']==1)&(df2['brand_cn_fill'].notnull())]\n",
    "# test=df2[(df2['mark']==1)&(df2['brand_cn_fill'].isnull())]\n",
    "# print(train.shape)\n",
    "# print(valid.shape)\n",
    "# print(test.shape)\n",
    "# print(len(train)+len(valid)+len(test)==len(df2))\n",
    "\n",
    "# def getLabel(sentence, loc_name, org_name):\n",
    "#     label = []\n",
    "#     for i in sentence:\n",
    "#         if i in loc_name:\n",
    "#             label.append('S')\n",
    "#         elif i in org_name:\n",
    "#             label.append('E')\n",
    "#         else:\n",
    "#             label.append('O')\n",
    "#     return \"\".join(label)\n",
    "\n",
    "\n",
    "# def re_ner(sentence, loc_name, org_name):\n",
    "#     ne_list = []\n",
    "#     label = getLabel(sentence, loc_name, org_name)\n",
    "    \n",
    "#     pattern = re.compile('SO*E')\n",
    "#     ne_label = re.finditer(pattern, label)\n",
    "\n",
    "#     for ne in ne_label:\n",
    "#         ne_list.append(sentence[int(ne.start()):int(ne.end())])\n",
    "#     return ','.join(ne_list)\n",
    "\n",
    "# cn_brands=df2[df2['mark']==0]['brand_cn'].unique().tolist()\n",
    "# print(len(cn_brands))\n",
    "\n",
    "# test1=test.drop_duplicates()[:1000]\n",
    "\n",
    "# test1['brand_cn_test']=''\n",
    "\n",
    "# for i in tqdm_notebook(cn_brands):\n",
    "#     s=i[0]\n",
    "#     e=i[-1]\n",
    "#     test1.loc[test1['brand_cn_test']=='','brand_cn_test']=test1[test1['brand_cn_test']=='']['desc'].apply(lambda x:re_ner(x,[s],[e]))\n",
    "#     gc.collect()\n",
    "\n",
    "# en_brands=df2[df2['mark']==0]['brand_en'].unique().tolist()\n",
    "# print(len(en_brands))\n",
    "\n",
    "# test1['brand_en_test']=''\n",
    "\n",
    "# for i in tqdm_notebook(en_brands):\n",
    "#     s=i[0]\n",
    "#     e=i[-1]\n",
    "#     test1.loc[test1['brand_en_test']=='','brand_en_test']=test1[test1['brand_en_test']=='']['desc'].apply(lambda x:re_ner(x,[s],[e]))\n",
    "#     gc.collect()\n",
    "\n",
    "# leng=1000\n",
    "# c1=test1[test1['brand_cn_test']=='']\n",
    "# print(len(c1)/leng)\n",
    "\n",
    "# c2=test1[test1['brand_en_test']=='']\n",
    "# print(len(c2)/leng)\n",
    "\n",
    "# c3=test1[test1['brand_en_test']!='']\n",
    "# c3[['desc','brand_cn_test','brand_en_test']].sample(5)\n",
    "\n",
    "# test1['brand_cn_test_1']=''\n",
    "\n",
    "# for i in tqdm_notebook(cn_brands):\n",
    "#     test1.loc[(test1['brand_cn_test_1']=='')&(test1['desc'].str.contains(i)),'brand_cn_test_1']=i\n",
    "#     gc.collect()\n",
    "\n",
    "# test1['brand_en_test_1']=''\n",
    "# for i in tqdm_notebook(en_brands):\n",
    "#     test1.loc[(test1['brand_en_test_1']=='')&(test1['desc'].str.contains(i)),'brand_en_test_1']=i\n",
    "#     gc.collect()\n",
    "\n",
    "# leng=1000\n",
    "# c1=test1[test1['brand_cn_test_1']=='']\n",
    "# print(len(c1)/leng)\n",
    "\n",
    "# c2=test1[test1['brand_en_test_1']=='']\n",
    "# print(len(c2)/leng)\n",
    "\n",
    "# \"\"\"英文提取非常不正确，所以通过dict将英文全部转换为中文，然后提取中文brand\"\"\"\n",
    "\n",
    "# cc=test1[test1['brand_cn_test_1']!='']\n",
    "# print(cc[['desc','brand_cn_test_1']].head(20))\n",
    "\n",
    "# s='L\\OCC'\n",
    "# if \"\\\\\" in s:\n",
    "#     print('yes')\n",
    "\n",
    "# all_cn_brands=df2[df2['mark']==0]['brand_cn'].unique().tolist()+df2[df2['mark']==0]['brand_cn_fill'].unique().tolist()\n",
    "# all_cn_brands=list(set(all_cn_brands))\n",
    "# for i in all_cn_brands:\n",
    "#     if \"\\\\\" in i:\n",
    "#         all_cn_brands.remove(i)\n",
    "# print(len(all_cn_brands))\n",
    "\n",
    "# all_en_brands=df2[df2['mark']==0]['brand_en'].unique().tolist()+df2[df2['mark']==0]['brand_en_fill'].unique().tolist()\n",
    "# all_en_brands=list(set(all_en_brands))\n",
    "# for i in all_en_brands:\n",
    "#     if \"\\\\\" in i:\n",
    "#         all_en_brands.remove(i)\n",
    "# print(len(all_en_brands))\n",
    "\n",
    "# test1['brand_cn_test_2']=''\n",
    "# for i in tqdm_notebook(all_cn_brands):\n",
    "#     test1.loc[(test1['brand_cn_test_2']=='')&(test1['desc'].str.contains(i)),'brand_cn_test_2']=i\n",
    "#     gc.collect()\n",
    "\n",
    "# leng=1000\n",
    "# c11=test1[test1['brand_cn_test_2']=='']\n",
    "# print(len(c11)/leng)\n",
    "\n",
    "# check=test1[test1['brand_cn_test_2']!='']\n",
    "# print(check[['desc','brand_cn_test_2']].head(30))\n",
    "\n",
    "# print(train.shape)\n",
    "# print(valid.shape)\n",
    "# print(test.shape)\n",
    "\n",
    "# testdf=test.copy()\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# train_brand=train[['brand_cn','brand_en']].drop_duplicates()\n",
    "# en_cn=dict(zip(train_brand['brand_en'],train_brand['brand_cn']))\n",
    "# print(len(en_cn))\n",
    "\n",
    "# testdf['desc_1']=testdf['desc']\n",
    "\n",
    "# testdf=testdf.reset_index(drop=True)\n",
    "\n",
    "# leng=len(testdf)\n",
    "# batch=10000\n",
    "# group=int(leng/batch)+1\n",
    "\n",
    "# fill_rate=[]\n",
    "\n",
    "# res=pd.DataFrame()\n",
    "# for i in range(group):\n",
    "#     print('BATCH:%d'%i)\n",
    "#     start=i*batch\n",
    "#     end=(i+1)*batch\n",
    "#     if end>leng:\n",
    "#         end=leng\n",
    "#     tmp=testdf[start:end]\n",
    "#     for en in tqdm_notebook(train['brand_en'].unique().tolist()):\n",
    "#         tmp.loc[tmp['desc_1'].str.contains(en),'desc_1']=tmp[tmp['desc_1'].str.contains(en)]['desc_1'].apply(lambda x:x.replace(en,en_cn[en]))\n",
    "#     for cn in tqdm_notebook(train['brand_cn'].unique().tolist()):\n",
    "#         tmp.loc[tmp['desc_1'].str.contains(cn),'brand_cn_test_3']=cn\n",
    "#         gc.collect()\n",
    "#     rate=len(tmp[tmp['brand_cn_test_3'].notnull()])/len(tmp)\n",
    "#     print(rate)\n",
    "#     fill_rate.append(rate)\n",
    "#     res=pd.concat([res,tmp[['id','desc','desc_1','brand_cn_test_3']]],axis=0)\n",
    "#     print('-'*40)\n",
    "\n",
    "# check1=res[res['brand_cn_test_3'].isnull()]\n",
    "# check2=res[res['brand_cn_test_3'].notnull()]\n",
    "# print(len(check1)+len(check2)==len(testdf))\n",
    "\n",
    "# print(len(check2)/len(testdf))\n",
    "\n",
    "# print(res[['desc_1','brand_cn_test_3']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
